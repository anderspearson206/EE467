{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTZ74veMIX6Q"
      },
      "source": [
        "# EE 467 Lab 6: Ensemble Learning and Random Forest\n",
        "\n",
        "Welcome to lab 6 of EE 467! Today we are going to learn and try out **ensemble learning** algorithms, which make use of multiple learning algorithms to achieve better performance than any of them. We will apply four kinds of common ensembles to the Kaggle credit card fraud detection problem: **voting, bagging, boosting and stacking**. We will also try **random forest** learning, which is a special kind of bagging ensemble that consists of decision trees. Like the previous lab, all algorithms are evaluated by **accuracy, precision, recall and F1-score**.\n",
        "\n",
        "## Pre-processing / Feature Extraction\n",
        "\n",
        "Let's start from the end of lab 5. First of all, we will load the credit card transaction dataset and re-do all the feature scaling and dataset splitting steps in the last lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cpcW1lO0P0Yz"
      },
      "outputs": [],
      "source": [
        "!tar -xf credit-card.tar.xz "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIDzoEQVIX6R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Kaggle credit card transactions dataset...\n",
            "Scaling transaction time and amount features...\n",
            "Performing feature-label / train-test splits...\n",
            "Completed.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "## [ Loading Dataset ]\n",
        "print(\"Loading Kaggle credit card transactions dataset...\")\n",
        "df = pd.read_csv(\"./creditcard.csv\")\n",
        "\n",
        "## [ Feature Scaling ]\n",
        "print(\"Scaling transaction time and amount features...\")\n",
        "# Convert transaction time from seconds to hours in a day\n",
        "df[\"Time\"] = (df[\"Time\"]/(60*60))%24\n",
        "# Scale time features with StandardScaler (suitable for normally distributed data)\n",
        "df[\"Time\"] = StandardScaler().fit_transform(df[\"Time\"].values[:, None])\n",
        "# Scale amount with RobustScaler (robust to outliers, useful for skewed distributions)\n",
        "df[\"Amount\"] = RobustScaler().fit_transform(df[\"Amount\"].values[:, None])\n",
        "\n",
        "## [ Feature-label / train-test splits ]\n",
        "print(\"Performing feature-label / train-test splits...\")\n",
        "\n",
        "# Get feature and label values from original dataset\n",
        "feat_all = df.drop([\"Class\"], axis=1).values\n",
        "y_all = df[\"Class\"].values\n",
        "\n",
        "# Split samples into training and test sets\n",
        "feat_train, feat_test, y_train, y_test = train_test_split(\n",
        "    feat_all, y_all, test_size=0.4, random_state=0\n",
        ")\n",
        "\n",
        "print(\"Completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us6s354jIX6S"
      },
      "source": [
        "During this lab we will use two utility functions from `lab_7_util`. The `timeit` function, which you should be fairly familiar with, times Python operations happening within the corresponding `with` block. The `evaluate_model` function evaluates a trained classification model on the test set and then prints the above-mentioned metrics we are interested about."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzxP3t4kIX6S",
        "tags": []
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'evaluate_model' from 'lab_6_util' (c:\\Users\\Anders\\Documents\\EE\\EE467\\lab6\\lab_6_util.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlab_6_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timeit, evaluate_model\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Time the training of logistic regression classifier\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m timeit(\u001b[33m\"\u001b[39m\u001b[33mTraining logistic regression classifier\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'evaluate_model' from 'lab_6_util' (c:\\Users\\Anders\\Documents\\EE\\EE467\\lab6\\lab_6_util.py)"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from lab_6_util import timeit, evaluate_model\n",
        "\n",
        "# Time the training of logistic regression classifier\n",
        "with timeit(\"Training logistic regression classifier\"):\n",
        "    logistic_model = LogisticRegression(max_iter=200).fit(feat_train, y_train)\n",
        "\n",
        "# Evaluate trained model and print metrics\n",
        "evaluate_model(logistic_model, \"logistic regression classifier\", feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx2Y-Yo4IX6S"
      },
      "source": [
        "## Voting\n",
        "\n",
        "The simplest kind of ensemble is a **voting ensemble**. Like a group of people making decisions through a majority vote, a voting ensemble contains multiple classification models, usually implemented from different algorithms. During training, each model learns independently from others. To make a prediction using the ensemble, each model \"votes\" by providing its own prediction computed from the sample features. The final predicted label of the ensemble is then the class with most \"votes\" from different models.\n",
        "\n",
        "For classification models that output a probability distribution over all classes, there is an alternative voting mechanism called **soft voting**. In soft voting, we average the probability of a particular class for all classifiers, and refer to it as the ensemble probability of a class. The ensemble prediction is then the class with the highest ensemble probability. Soft voting largely avoids the **tie-breaking problem** of hard voting, in which two or more majority classes exist with the same number of votes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8SfGkVsIX6T"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'evaluate_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     14\u001b[39m voting_ensemble = VotingClassifier(\n\u001b[32m     15\u001b[39m     estimators=[\n\u001b[32m     16\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mlogistic\u001b[39m\u001b[33m\"\u001b[39m, LogisticRegression(max_iter=\u001b[32m200\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     voting=\u001b[33m\"\u001b[39m\u001b[33mhard\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m ).fit(feat_train, y_train)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Evaluate the voting ensemble classifier\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mevaluate_model\u001b[49m(voting_ensemble, \u001b[33m\"\u001b[39m\u001b[33mvoting ensemble\u001b[39m\u001b[33m\"\u001b[39m, feat_test, y_test)\n",
            "\u001b[31mNameError\u001b[39m: name 'evaluate_model' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "## [  ]\n",
        "# 1) Create and evaluate a voting ensemble (`VotingClassifier`) with the following sub-classifiers:\n",
        "#    - A logistic regression classifier\n",
        "#      (Hint: increase maximum iteration to 200 to avoid non-convergence warning)\n",
        "#    - A Gaussian naive Bayes (`GaussianNB`) classifier\n",
        "#    - A decision tree classifier\n",
        "# 2) Evaluate the performance of each sub-classifier on the test set\n",
        "#    (Hint: obtain the sub-classifiers through `voting_ensemble.named_estimators_`)\n",
        "# 3) Change the voting mechanism to soft voting. Does the performance of the ensemble improved?\n",
        "voting_ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"logistic\", LogisticRegression(max_iter=200)),\n",
        "        (\"naive_bayes\", GaussianNB()),\n",
        "        (\"decision_tree\", DecisionTreeClassifier()),\n",
        "    ],\n",
        "    voting=\"hard\",\n",
        ").fit(feat_train, y_train)\n",
        "# Evaluate the voting ensemble classifier\n",
        "evaluate_model(voting_ensemble, \"voting ensemble\", feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOZ0xVfIX6U"
      },
      "source": [
        "## Bagging / Random Forest\n",
        "\n",
        "**Bagging ensemble** is a kind of ensemble built upon voting. Compared to regular voting ensembles, a bagging ensemble only contains several classifiers of the **same type** (implementing the same algorithm and using the same hyper-parameter settings), each of which is trained on **a random subset of samples (and / or features)**. Bagging reduces over-fitting of the original classification model by introducing randomization into its construction and then making an ensemble out of it. It works best with strong and complex machine learning models such as neural networks and deep decision trees.\n",
        "\n",
        "In the following code cell, we will train a few **logistic regression bagging ensemble** with different settings. We will alter the number of (sub-)classifiers, proportion of samples and features and study their influence on the performance of the bagging ensemble:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o2y_CV9yIX6V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training bagging ensemble (10 sub-classifiers, 20% samples) started...\n",
            "Training bagging ensemble (10 sub-classifiers, 20% samples) completed. Elapsed time: 4.19s\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'evaluate_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m     model.fit(feat_train, y_train)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Evaluate each bagging classifier\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mevaluate_model\u001b[49m(model, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbagging ensemble (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m, feat_test, y_test)\n",
            "\u001b[31mNameError\u001b[39m: name 'evaluate_model' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "## [ TODO ]\n",
        "# 1) Create and evaluate a logistic regression bagging ensemble (`BaggingClassifier`)\n",
        "#    with 10 sub-classifiers, each using 20% of samples.\n",
        "# 2) Based on the ensemble of question 1, increase the number of sub-classifiers to 30\n",
        "#    and evaluate again.\n",
        "# 3) Based on the ensemble of question 1, increase the proportion of training samples for\n",
        "#    each classifier to 60% and evaluate again.\n",
        "# 4) Based on the ensemble of question 1, enable boostrapping of features, set the\n",
        "#    proportion of features to 50% and evaluate again.\n",
        "bagging_models = {\n",
        "    \"10 sub-classifiers, 20% samples\": BaggingClassifier(\n",
        "        estimator=LogisticRegression(max_iter=200),\n",
        "        n_estimators=10,\n",
        "        max_samples=0.2,\n",
        "    ),\n",
        "    \"30 sub-classifiers, 20% samples\": BaggingClassifier(\n",
        "        estimator=LogisticRegression(max_iter=200),\n",
        "        n_estimators=30,\n",
        "        max_samples=0.2,\n",
        "    ),\n",
        "    \"10 sub-classifiers, 60% samples\": BaggingClassifier(\n",
        "        estimator=LogisticRegression(max_iter=200),\n",
        "        n_estimators=10,\n",
        "        max_samples=0.6,\n",
        "    ),\n",
        "    \"10 sub-classifiers, 50% features\": BaggingClassifier(\n",
        "        estimator=LogisticRegression(max_iter=200),\n",
        "        n_estimators=10,\n",
        "        bootstrap_features=True,\n",
        "        max_features=0.5,\n",
        "    ),\n",
        "}\n",
        "\n",
        "for setting, model in bagging_models.items():\n",
        "    # Train each bagging classifier\n",
        "    with timeit(f\"Training bagging ensemble ({setting})\"):\n",
        "        model.fit(feat_train, y_train)\n",
        "    # Evaluate each bagging classifier\n",
        "    evaluate_model(model, f\"bagging ensemble ({setting})\", feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q209h-1wIX6V"
      },
      "source": [
        "In practice, bagging ensemble is often built upon decision tree classifiers. When each decision tree within the ensemble learns from **both a subset of samples and a subset of features**, the resulting bagging ensemble is called a **random forest**. Below code trains and compares the performance of a single decision tree and two random forests with 40 and 100 decision tree classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME6ks2a3IX6W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Number of CPUs for ensemble learning methods\n",
        "N_ENSEMBLE_CPUS = max(os.cpu_count()//2, 1)\n",
        "\n",
        "# A regular decision tree classifier\n",
        "with timeit(\"Training DT classifier\"):\n",
        "    dt_model = DecisionTreeClassifier()\n",
        "    dt_model.fit(feat_train, y_train)\n",
        "\n",
        "## [ TODO ]\n",
        "# 1) Train a random forest classifier with 40 decision trees\n",
        "# 2) Train a random forest classifier with 100 decision trees\n",
        "#    (Hint: set `n_jobs` to `N_ENSEMBLE_CPUS` to train the random forest in parallel and reduce training time)\n",
        "rf_40_model = NotImplemented\n",
        "rf_100_model = NotImplemented\n",
        "\n",
        "# Evaluate previous models\n",
        "evaluate_model(dt_model, \"DT classifier\", feat_test, y_test)\n",
        "evaluate_model(rf_40_model, \"Random forest classifier (40 DTs)\", feat_test, y_test)\n",
        "evaluate_model(rf_100_model, \"Random forest classifier (100 DTs)\", feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxMyBPQBIX6W"
      },
      "source": [
        "## Boosting\n",
        "\n",
        "Boosting is an ensemble learning technique that aims to combine **a set of weak learners** (a classifier that is only **slightly better** than a random classifier) into a strong learner. It is able to reduce both the bias and variance of the original classification models. A boosting algorithm usually consists of **iteratively learning weak classifiers** with respect to a distribution and **adding them to a final strong classifier**. Weak classifiers are typically weighted in some way that is related to its performance. After a weak learner is added, sample weights are re-adjusted so that **misclassified samples are stressed** and correctly classified samples are paid less attention to. This causes future weak learners to focus more on samples that previous weak learners fail, thus making the ensemble more robusting against variations in sample features.\n",
        "\n",
        "In the following code cell, we will try two kinds of boosting ensembles: **[AdaBoost](https://en.wikipedia.org/wiki/AdaBoost) and [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting)**. Both use one-level (as opposed to full, deep) decision trees as base weak classifiers. AdaBoost adjusts the weights of training samples and weak classifiers based on the accuracy, while gradient boosting adjusts the weights by differentiating through the target loss and computing the correponsing gradient for gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE1-tgJkIX6W",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "\n",
        "# AdaBoost: adjusts weights based on misclassification rates (50 default weak learners)\n",
        "with timeit(\"Training AdaBoost classifier (50 DTs)\"):\n",
        "    adaboost_model = AdaBoostClassifier()\n",
        "    adaboost_model.fit(feat_train, y_train)\n",
        "\n",
        "# Gradient boosting: sequentially corrects errors using gradient descent (40 estimators)\n",
        "with timeit(\"Training gradient boosting classifier\"):\n",
        "    gb_model = GradientBoostingClassifier(n_estimators=40)\n",
        "    gb_model.fit(feat_train, y_train)\n",
        "\n",
        "# Evaluate boosting models\n",
        "evaluate_model(adaboost_model, \"AdaBoost classifier\", feat_test, y_test)\n",
        "evaluate_model(gb_model, \"gradient boosting classifier\", feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dBxGmOCIX6X"
      },
      "source": [
        "## Stacking\n",
        "\n",
        "The last ensemble learning scheme is **stacking**, which is also the most sophisticated one among the four we have introduced today. Like all previous types of ensemble, a stacking ensemble contains a number of classifiers, each possibly using a distinct machine learning algorithm. However, we would perform $K$-fold **cross validation** during training on each classifier, so each classifier actually has $K$ clones that are trained on different parts of the training samples. The cross validation also provides us with the **validation predictions for all samples**, gathered from the $K$ clones. After training all base classifiers, we collect and concatenate the validation predictions from clones of different classifiers as features, and then **train a meta-classifier** that predicts the sample label for the whole ensemble.\n",
        "\n",
        "\n",
        "To predict labels for the test set (and any other unseen dataset) samples, we apply the features to all $K$ clones of all classifiers. For the $K$ clones of the same classifier, we **average their outputs** which are usually the probability distribution over all classes. Like the training data, we then **concatenate the averaged outputs** from different classifiers as features, and finally pass them to the meta-classifier to obtain predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hubsNFsAIX6X"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "with timeit(\"Training stacking ensemble\"):\n",
        "    # Create a stacking ensemble with a logistic regression meta-classifier and three sub-classifiers\n",
        "    stacking_ensemble = StackingClassifier([\n",
        "        (\"Random forest\", RandomForestClassifier(n_estimators=40)),\n",
        "        (\"Logistic\", LogisticRegression(max_iter=200)),\n",
        "        (\"SVM\", LinearSVC(max_iter=1500))\n",
        "    ], LogisticRegression(), n_jobs=N_ENSEMBLE_CPUS)\n",
        "    # Train the stacking ensemble\n",
        "    stacking_ensemble.fit(feat_train, y_train)\n",
        "\n",
        "# Evaluate the stacking ensemble\n",
        "evaluate_model(stacking_ensemble, \"stacking ensemble\", feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMhCX9MbIX6X",
        "tags": []
      },
      "source": [
        "## References\n",
        "\n",
        "1. Emsemble Learning: https://en.wikipedia.org/wiki/Ensemble_learning\n",
        "2. Ensemble Learning in Machine Learning: https://towardsdatascience.com/ensemble-learning-in-machine-learning-getting-started-4ed85eb38e00\n",
        "3. Random Forest: https://en.wikipedia.org/wiki/Random_forest\n",
        "4. Boosting: https://en.wikipedia.org/wiki/Boosting_(machine_learning)\n",
        "5. AdaBoost: https://en.wikipedia.org/wiki/AdaBoost\n",
        "6. Gradient Boosting: https://en.wikipedia.org/wiki/Gradient_boosting"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
